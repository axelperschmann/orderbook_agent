{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from helper.rl_framework import *\n",
    "from helper.rl_functions import *\n",
    "from helper.orderbook_container import OrderbookContainer\n",
    "from helper.manage_orderbooks_v2 import *\n",
    "from helper.orderbook_trader import *\n",
    "from helper.Q_learning import QLearn, QLearnEnvironment, state_as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/720 [00:00<00:36, 19.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load Training Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:29<00:00, 21.92it/s]\n",
      "  0%|          | 0/720 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 720 orderbooks from file '../data/3000orderbooks'.\n",
      "OrderbookContainer from 2016-11-08T10:00\n",
      "  499 bids (best: 705.0)\n",
      "  407 asks (best: 705.45)\n",
      "  kind: 'orderbook'\n",
      "\n",
      "# Load Validation Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:32<00:00, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 720 orderbooks from file '../data/3000orderbooks'.\n",
      "OrderbookContainer from 2016-11-08T22:01\n",
      "  548 bids (best: 712.99)\n",
      "  410 asks (best: 713.36)\n",
      "  kind: 'orderbook'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# filename = '../../data/snapshots/orderbooks_USDT_BTC_range1.15_samplesNone_snapshot2017-01-11T17:19.dict'\n",
    "filename = '../data/3000orderbooks'\n",
    "currency_pair = 'USDT_BTC'\n",
    "\n",
    "samples = 720\n",
    "print(\"# Load Training Set\")\n",
    "orderbooks_train = load_orderbook_snapshot(infile=filename, first_line=0, last_line=samples)\n",
    "print(orderbooks_train[0])\n",
    "\n",
    "print(\"\")\n",
    "print(\"# Load Validation Set\")\n",
    "orderbooks_val = load_orderbook_snapshot(infile=filename, first_line=samples, last_line=2*samples)\n",
    "print(orderbooks_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 4  # Time horizon: 10 periods -> P*T = 20 minutes\n",
    "P = 30  # period length\n",
    "print(\"T={}, P={}\".format(T, P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split orderbook array into non-overlapping episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_episodes(orderbooks, episode_length):\n",
    "    episode_windows = []\n",
    "    for e in range(0, int(len(orderbooks) / episode_length)):\n",
    "        window = [ob.copy() for ob in orderbooks[e*episode_length:(e+1)*episode_length]]\n",
    "\n",
    "        # plot_episode(window, volume=V, outfile='graphs/episode_window{}'.format(e))\n",
    "        episode_windows.append(window)\n",
    "    return episode_windows\n",
    "\n",
    "episode_windows_train = create_episodes(orderbooks_train, episode_length=T*P)\n",
    "episode_windows_val = create_episodes(orderbooks_val, episode_length=T*P)\n",
    "\n",
    "print(\"Training Episodes  : {}, episode length: {}, start at: {}\".format(len(episode_windows_train), len(episode_windows_train[0]), episode_windows_train[0][0].timestamp))\n",
    "print(\"Validation Episodes: {}, episode length: {}, start at: {}\".format(len(episode_windows_val), len(episode_windows_val[0]), episode_windows_val[0][0].timestamp))\n",
    "# plot_episode(episode_windows_val[0], volume=10)\n",
    "# plot_episode(episode_windows_val[0], volume=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STATE_DIM = 2\n",
    "NUM_ACTIONS = 11\n",
    "actions = list(np.linspace(-1, 5, num=NUM_ACTIONS))\n",
    "print(\"available actions: {}\".format(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def round_custombase(val, *, base):\n",
    "    return float(round(float(val) / base) * base)\n",
    "\n",
    "test = round_custombase(12.43, base=5)\n",
    "print(type(test), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = QLearnEnvironment(volume=100)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(state_as_string(time_left=3, volume_left=1.0, orderbook=episode_windows_train[0][1]))\n",
    "print(state_as_string(time_left=3, volume_left=1.0))  # , orderbook=episode_windows_train[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tt in tqdm(range(T)[::-1]):\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def optimal_strategy(V, T, decisionfrequency, vol_intervals, actions, verbose=True):\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    print(\"V: {}, T: {}, decisionfrequency: {}, vol_intervals: {}, num_actions: {}\".format(V, T, decisionfrequency, vol_intervals, len(actions)))\n",
    "    print(\"actions: {}\".format(actions))\n",
    "    volumes = np.linspace(0, 1, num=vol_intervals+1)[1:][::-1] # skip volumes=0\n",
    "    \n",
    "    volumes_base = float(V)/vol_intervals\n",
    "    print(\"volumes_base: {}\".format(volumes_base))\n",
    "    print(\"volumes: {}\".format(volumes))\n",
    "    ql = QLearn(actions=actions, vol_intervals=vol_intervals, V=V, T=T, decisionfrequency=decisionfrequency)\n",
    "    print(\"V: \", ql.V)\n",
    "\n",
    "    H = T*decisionfrequency\n",
    "\n",
    "    for tt in tqdm(range(T)[::-1]):\n",
    "        trading_startpoint = decisionfrequency*tt\n",
    "        time_left = T-tt\n",
    "\n",
    "        for episode in tqdm(episode_windows_train):\n",
    "            center = episode[trading_startpoint].get_center()\n",
    "            # ask = episode[trading_startpoint].get_ask()\n",
    "            initial_center = episode[0].get_center()\n",
    "            \n",
    "            for vol in volumes:\n",
    "                if tt == 0:\n",
    "                    if vol != 1.:\n",
    "                        # at t=0 we always have 100% of the volume left.\n",
    "                        print(\"x\", vol)\n",
    "                        break\n",
    "                \n",
    "                for a in actions:\n",
    "                    state = state_as_string(time_left=time_left, volume_left=vol)  #, orderbook=episode[trading_startpoint])\n",
    "                    \n",
    "                    if vol == 0:\n",
    "                        volume_left = 0\n",
    "                        cost = 0\n",
    "                    else:\n",
    "                        ots = OrderbookTradingSimulator(orderbooks=episode[trading_startpoint:], volume=vol*V, tradingperiods=T-tt,\n",
    "                                                        decisionfrequency=decisionfrequency)\n",
    "                        limit = center + a\n",
    "\n",
    "                        ots.trade(limit = limit)  # agression_factor=a)\n",
    "                    \n",
    "                        volume_left = ots.volume\n",
    "                        volume_left_rounded = round_custombase(volume_left, base=volumes_base)\n",
    "                        \n",
    "                        volume_traded = ots.history.volume_traded.values[-1]\n",
    "                        volume_traded_rounded = round_custombase(volume_traded, base=volumes_base)\n",
    "                        \n",
    "                        assert volume_left_rounded + volume_traded_rounded - vol*V <= 1.e-8, \"{} {} {} {}\".format(\n",
    "                            volume_left_rounded, volume_traded_rounded, vol, V)\n",
    "                        \n",
    "                        cashflow = ots.history.cashflow[-1]\n",
    "                        \n",
    "                        avg = ots.history.avg[-1]\n",
    "                        \n",
    "                        # manually compute costs, since we have to think in discrete volume steps (rounding ...)\n",
    "                        cost = volume_traded_rounded * (avg - initial_center) / initial_center\n",
    "                    \n",
    "                    new_state = state_as_string(time_left=time_left-1, volume_left=volume_left_rounded/V)  #, orderbook=ots.masterbook)\n",
    "                    \n",
    "                    print(state, a, cost, new_state)\n",
    "                    \n",
    "                    ql.learn(state, a, cost, new_state)\n",
    "                    \n",
    "            ql.plot_Q(outfile=\"../graphs/Q_function_{}_action\".format(T-tt), outformat='pdf', z_represents='action', verbose=verbose)\n",
    "            ql.plot_Q(outfile=\"../graphs/Q_function_{}_Q\".format(T-tt), outformat='pdf', z_represents='Q', verbose=verbose)\n",
    "        ql.save(\"../pickles/Q_function_{}\".format(timestamp))\n",
    "    plot_episode(episode, volume=V)\n",
    "    return ql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V = 100\n",
    "print(\"V={}, T={}, P={}\".format(V, T, P))\n",
    "ql = optimal_strategy(V=V, T=T, decisionfrequency=P, vol_intervals=10, actions=actions)\n",
    "ql.plot_Q(z_represents='action')\n",
    "ql.plot_Q(z_represents='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ql.plot_Q(z_represents='action')\n",
    "ql.plot_Q(z_represents='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "V=100\n",
    "T=4\n",
    "# P=15\n",
    "ql = QLearn(actions = actions, vol_intervals=10)\n",
    "# ql = ql.load(\"pickles/Q_function_e375_T4_P2_V200\")\n",
    "ql = ql.load(\"pickles/Q_function_e12_T4_P15_V100_I10\")\n",
    "ql.plot_Q(V, T, z_represents='action')\n",
    "ql.plot_Q(V, T, z_represents='Q')\n",
    "\n",
    "print(ql)\n",
    "# ql.plot_Q(V, T, z_represents='both')\n",
    "\n",
    "# for key in sorted(ql.q)[::-1]:\n",
    "#     print(\"\")\n",
    "#     print(key)\n",
    "#     print(ql.q[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(episode_windows[0][0].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_Q(V, H, T, ql, episode_windows):\n",
    "    costs_list = []\n",
    "    decisionfrequency = int(H/T)\n",
    "\n",
    "    for episode in tqdm(episode_windows):\n",
    "        costs = {}\n",
    "        volume = V\n",
    "        \n",
    "        ## Learned strategy\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode, volume=volume, tradingperiods=T,\n",
    "                                        decisionfrequency=decisionfrequency)\n",
    "        for tt in range(1, T+1, 1)[::-1]:\n",
    "            new_vol = round_custombase(ots.volume, base=ql.vol_intervals)    \n",
    "            if new_vol > 0:\n",
    "                state = state_as_string(time_left=tt, volume_left=new_vol/V)  #, orderbook=ots.get_next_masterbook())\n",
    "                action = ql.chooseAction(state)\n",
    "\n",
    "                # print(state, action)\n",
    "                obs = episode[decisionfrequency * (T-tt)].copy()\n",
    "                # obs = [elem.copy() for elem in obs_]\n",
    "            \n",
    "                ask = obs.get_ask()\n",
    "                # center = ots.masterbook.get_center()\n",
    "                limit = ask * (1. + (action/100.))\n",
    "            else:\n",
    "                # theoreticall done\n",
    "                limit == None\n",
    "            ots.trade(limit = limit, extrainfo={'ACTION':action})\n",
    "        costs['learned'] = ots.history.cost.sum()\n",
    "        # print(\"learned\")\n",
    "        # display(ots.history)\n",
    "        \n",
    "        ## limit + 1\n",
    "        a=0.1\n",
    "        lim = episode[0].get_ask() * (1. + (a/100.))\n",
    "        # print(\"\\n### Fixed limit at: {} (ASK+4) ###\".format(lim))\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode, volume=volume, tradingperiods=T,\n",
    "                                        decisionfrequency=decisionfrequency)\n",
    "        for i in range(T):\n",
    "            ots.trade(limit = lim)\n",
    "        costs['ask*1.001'] = ots.history.cost.sum()\n",
    "        \n",
    "        \n",
    "        ## limit + 2.5\n",
    "        a=0.2\n",
    "        lim = episode[0].get_ask() * (1. + (a/100.))\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode, volume=volume, tradingperiods=T,\n",
    "                                        decisionfrequency=decisionfrequency)\n",
    "        for i in range(T):\n",
    "            ots.trade(limit = lim)\n",
    "        costs['ask*1.002'] = ots.history.cost.sum()\n",
    "        # print(\"1.002\")\n",
    "        # display(ots.history)\n",
    "        \n",
    "        \n",
    "        ## limit + 3\n",
    "        lim = episode[0].get_ask()\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode, volume=volume, tradingperiods=T,\n",
    "                                        decisionfrequency=decisionfrequency)\n",
    "        for i in range(T):\n",
    "            ots.trade(limit = lim)\n",
    "        costs['ask*1'] = ots.history.cost.sum()\n",
    "        \n",
    "        ## limit + 4\n",
    "        a=0.5\n",
    "        lim = episode[0].get_ask() * (1. + (a/100.))\n",
    "        # print(\"\\n### Fixed limit at: {} (ASK+4) ###\".format(lim))\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode, volume=volume, tradingperiods=T,\n",
    "                                        decisionfrequency=decisionfrequency)\n",
    "        for i in range(T):\n",
    "            ots.trade(limit = lim)\n",
    "        costs['ask*1.005'] = ots.history.cost.sum()\n",
    "        \n",
    "        \n",
    "        ## market order\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode, volume=volume, tradingperiods=T,\n",
    "                                        decisionfrequency=decisionfrequency)\n",
    "        ots.trade(limit = None)\n",
    "        costs['market'] = ots.history.cost.sum()\n",
    "        \n",
    "        \n",
    "        costs_list.append(costs)\n",
    "        \n",
    "    return costs_list\n",
    "        \n",
    "print(\"T={}, P={}\".format(T, P))\n",
    "print(ql.q.keys())\n",
    "costs_list_val = run_Q(V=100, H=T*P, T=T, ql=ql, episode_windows = episode_windows_val)\n",
    "costs_list_train = run_Q(V=100, H=T*P, T=T, ql=ql, episode_windows = episode_windows_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors=['r','g','b','y','magenta','grey']\n",
    "order = ['ask+1', 'ask+2.5', 'ask+3', 'ask+4','learned', 'last t', 'market']\n",
    "\n",
    "experiments = pd.DataFrame(costs_list_train)[order]\n",
    "# display(experiments)\n",
    "experiments.boxplot()\n",
    "plt.axvline(4.5, color='black')\n",
    "plt.axvline(5.5, color='black')\n",
    "plt.suptitle(\"Training Set\")\n",
    "plt.xlabel(\"Experiments\")\n",
    "plt.ylabel(\"Occured costs\")\n",
    "plt.savefig(\"boxplot_train.pdf\")\n",
    "# plt.ylim((0.2, 0.4))\n",
    "plt.show()\n",
    "\n",
    "experiments = pd.DataFrame(costs_list_val)[order]\n",
    "# display(experiments)\n",
    "experiments.boxplot()\n",
    "plt.axvline(4.5, color='black')\n",
    "plt.axvline(5.5, color='black')\n",
    "plt.suptitle(\"Validation Set\")\n",
    "plt.xlabel(\"Experiments\")\n",
    "plt.ylabel(\"Occured costs\")\n",
    "plt.savefig(\"boxplot_val.pdf\")\n",
    "plt.ylim((0.0, 0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = costs_list[0].keys()\n",
    "\n",
    "avg = {}\n",
    "for elem in costs_list:\n",
    "    for key in keys:\n",
    "        avg[key] = avg.get(key, 0) + elem[key]/len(costs_list)\n",
    "avg\n",
    "for i, key in enumerate(avg):\n",
    "    plt.scatter(i, avg[key], color=colors[i], label=key)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# states:\n",
    "# [volume_left, time_left]\n",
    "I = 5\n",
    "print(\"V: {}, T: {}, I: {}\".format(V, T, I))\n",
    "volumes_rounded = [I*x for x in range(V/I+1)]\n",
    "print(\"volume_left\", volumes_rounded)\n",
    "\n",
    "print(zip(volumes_rounded, range(T)))\n",
    "\n",
    "states = []\n",
    "for i in volumes_rounded:\n",
    "    for j in range(T):\n",
    "        states.append([i, j])\n",
    "display(states)\n",
    "\n",
    "qtable = np.zeros(len(states))\n",
    "display(qtable, qtable.shape)\n",
    "\n",
    "qtable[4, ]\n",
    "\n",
    "display(qtable, qtable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_RL(V, T, P, epochs, gamma=0.95, DECAY_RATE=0.005, epsilon=1., bufferSize=50, batchSize=30, verbose=False, log=None):\n",
    "    \n",
    "    model = base_model()\n",
    "    if log:\n",
    "        log = open('logs/RL_train_{}.log'.format(datetime.now().isoformat()[2:-10]), 'w')\n",
    "        log.write(\"RL training started\\n\")\n",
    "        log.write(\"Actions: {}\\n\".format(actions))\n",
    "        log.write(\"V={}, T={}, P={}\\n\".format(V, T, P))\n",
    "        log.write(\"Compiled model!\")\n",
    "    MAX_EXPLORATION_RATE = 1.\n",
    "    MIN_EXPLORATION_RATE = 0.05\n",
    "    \n",
    "    min_costs = np.inf\n",
    "\n",
    "    replay = Memory(bufferSize)\n",
    "    # stores tuples of (S, A, R, S')\n",
    "\n",
    "    for i_episode in tqdm(range(epochs)):\n",
    "        obs = episode_windows[0]  # episode_windows[i]  # Testcase with always the same, identical episode_window\n",
    "\n",
    "        ots = OrderbookTradingSimulator(volume=V, tradingperiods=T, decisionfrequency=P)\n",
    "\n",
    "        time_left = T\n",
    "        volume = V\n",
    "        action_history = []\n",
    "        state = np.array([time_left, volume])  # volume])\n",
    "\n",
    "        acc_cost = 0\n",
    "        for step in range(T):\n",
    "            qval = model.predict(state.reshape(1, STATE_DIM))\n",
    "            # print(\"     {}\".format(qval))\n",
    "\n",
    "            ob = obs[step*P]\n",
    " \n",
    "            if random.random() < epsilon:\n",
    "                # choose random action\n",
    "                #action = random.randint(0, len(actions)-1)\n",
    "                # action = round(random.random()*2.-1, 1)\n",
    "                action = random.choice(actions)\n",
    "            else:\n",
    "                # choose best action from Q(s,a) values\n",
    "                action = actions[np.argmin(qval)]\n",
    "            action_history.append(action)    \n",
    "            if verbose:\n",
    "                print(\"{}: action {}\".format(action, actions[action]))\n",
    "                \n",
    "            # if V > 0:\n",
    "            #     best_price = ob.get_ask()\n",
    "            # elif V < 0:\n",
    "            #     best_price = ob.get_bid()\n",
    "            # else:\n",
    "            #     assert(1 == 2), \"Error!\"\n",
    "            # lim = best_price - actions[action]\n",
    "            \n",
    "            orderbooks = obs[step*P:(step+1)*P]\n",
    "            info = ots.trade(orderbooks, agression_factor=action, verbose=False, extrainfo={'ACTION':action})\n",
    "\n",
    "\n",
    "            time_left -= 1\n",
    "            volume = ots.volume\n",
    "\n",
    "            new_state = np.array([time_left, volume])  # volume, \n",
    "            cost = ots.history.cost.values[-1]\n",
    "            if info['forced'].values[0]:\n",
    "                pass\n",
    "                # cost *= 3\n",
    "            acc_cost += cost\n",
    "\n",
    "            replay.add((state, action, cost, new_state))\n",
    "            if (replay.size() >= bufferSize):\n",
    "                # wait for buffer to be filled, before getting started with training\n",
    "                minibatch = replay.get_random_samples(batchSize)           \n",
    "\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                for memory in minibatch:\n",
    "                    state_m, action_m, cost_m, new_state_m = memory\n",
    "\n",
    "                    qval_old = model.predict(state_m.reshape(1, STATE_DIM))               \n",
    "                    y = np.zeros((1, NUM_ACTIONS))\n",
    "                    y[:] = qval_old[:]\n",
    "\n",
    "                    qval_new_m = model.predict(new_state_m.reshape(1, STATE_DIM), batch_size=1)\n",
    "                    maxQ = np.max(qval_new_m)\n",
    "\n",
    "                    update = cost_m + (gamma*maxQ)\n",
    "                    y[0][action_m] = update  # target output\n",
    "\n",
    "                    X_train.append(state_m.reshape(STATE_DIM,))\n",
    "                    y_train.append(y.reshape(NUM_ACTIONS,))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "\n",
    "                # print(\"Game #: %s\" % (i_episode,))\n",
    "                model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "            state = new_state\n",
    "            if volume == 0:\n",
    "                # display(ots.history)\n",
    "                break\n",
    "\n",
    "        # reduce exploration rate\n",
    "        if epsilon > MIN_EXPLORATION_RATE:\n",
    "            epsilon = MAX_EXPLORATION_RATE *   math.exp(- DECAY_RATE * i_episode)\n",
    "            \n",
    "        forced_trade = \"\"\n",
    "        if info['forced'].values[0]:\n",
    "            forced_trade = \", forced!\"\n",
    "        info = \"{:4d}/{}: epsilon={:5.3f}, acc_cost: {:0.5f}, steps: {} (t={}) {}\\n\"\\\n",
    "                .format(i_episode+1, epochs, epsilon,  acc_cost, step, ots.t, forced_trade)\n",
    "        if log:\n",
    "            log.write(info)\n",
    "        if min_costs > acc_cost:\n",
    "            min_costs = acc_cost\n",
    "            if log:\n",
    "                log.write(\"   {}\\n\".format(action_history))\n",
    "            \n",
    "            print(info)\n",
    "            print(\"   {}\".format(action_history))\n",
    "            display(ots.history)\n",
    "        # print(\"     {}\".format(action_history))\n",
    "    log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "V=30\n",
    "T=5\n",
    "P=2\n",
    "\n",
    "train_RL(V=V, T=T, P=P, epochs=300, verbose=False, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_Q(model, actions, V, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(V, T, P, epochs=1, overwrite_actions=None):\n",
    "    for i_episode in range(epochs):\n",
    "        obs = episode_windows[0]  # episode_windows[i]  # Testcase with always the same, identical episode_window\n",
    "\n",
    "        ots = OrderbookTradingSimulator(volume=V, tradingperiods=T, decisionfrequency=P)\n",
    "\n",
    "        time_left = P*T\n",
    "        volume = V\n",
    "\n",
    "        state = np.array([time_left, volume])  # , volume])\n",
    "        # state = discretize_state(state)\n",
    "\n",
    "        acc_cost = 0\n",
    "        for step in range(T):\n",
    "            qval = model.predict(state.reshape(1, STATE_DIM))\n",
    "            \n",
    "            action = actions[np.argmin(qval)]\n",
    "            \n",
    "            if overwrite_actions and step < len(overwrite_actions):\n",
    "                action = overwrite_actions[step]\n",
    "\n",
    "            ob = obs[step*P]\n",
    "\n",
    "            orderbooks = obs[step*P:(step+1)*P]\n",
    "            # info = ots.trade(orderbooks, limit=lim, verbose=False)\n",
    "            info = ots.trade(orderbooks, agression_factor=action, verbose=False, extrainfo={'ACTION':action})\n",
    "\n",
    "            time_left -= 1\n",
    "            volume = ots.volume\n",
    "            new_state = np.array([time_left, volume])  # , volume])\n",
    "            cost = ots.history.cost.values[-1]\n",
    "\n",
    "            acc_cost += cost\n",
    "\n",
    "            state = new_state\n",
    "            if volume == 0:\n",
    "                break\n",
    "\n",
    "        info = \"{:4d}/{}: acc_cost: {:0.5f}, steps: {} (t={})\"\\\n",
    "                .format(i_episode+1, epochs, acc_cost, step, ots.t)\n",
    "        print(info)\n",
    "    return ots.history\n",
    "hist = run(V=V, T=T, P=P)  #, overwrite_actions=[0,0,0,0,0,0,0,0,0])\n",
    "display(hist)\n",
    "hist = run(V=V, T=T, P=P, overwrite_actions=[0.24]*10)\n",
    "display(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_episode(episode_windows[3], volume=50, figsize=(5,3))\n",
    "episode_windows[3][90].plot(range_factor=1.015, figsize=(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_plots(x):\n",
    "    # episode_windows[3][x].plot(range_factor=1.015, figsize=(5,3))\n",
    "    return x\n",
    "\n",
    "from ipywidgets import interact\n",
    "interact(show_plots, x=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(obs))\n",
    "for vol in [1, 50, 100]:\n",
    "    market_order_price = []\n",
    "    ask_price = []\n",
    "    for i, ob in enumerate(obs):\n",
    "        market_order_price.append(ob.get_current_price(volume=vol))\n",
    "        ask_price.append(vol*ob.get_ask())\n",
    "\n",
    "    plt.plot(market_order_price, color='blue', marker='o', label='market order price')\n",
    "    plt.plot(ask_price, color='red', marker='*', label='ask price')\n",
    "                         \n",
    "                         \n",
    "    \n",
    "    plt.title(\"Market order price for {} shares\".format(vol))\n",
    "    plt.ylabel(\"price\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlim((-1,21))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
