{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from helper.rl_framework import *\n",
    "from helper.orderbook_container import OrderbookContainer\n",
    "from helper.manage_orderbooks import *\n",
    "from helper.orderbook_trader import *\n",
    "# from helper.RL_Agent import RLAgent\n",
    "from helper.RL_Agent_Specific import RLAgent_NN\n",
    "\n",
    "# Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V=100, T=4, P=15\n",
      "Actions:  -0.40, -0.05, 0.30, 0.65, 1.00\n",
      "Length of episodes_train: 541\n"
     ]
    }
   ],
   "source": [
    "filename_train = '/home/axel/data/small/obs_2016-11_USDT_BTC_maxVol100.dict'\n",
    "V = 100\n",
    "vol_intervals = 10\n",
    "T = 4\n",
    "P = 15\n",
    "state_variables=['volume','time']\n",
    "\n",
    "\n",
    "actions = list(np.linspace(-0.4, 1.0, num=5))\n",
    "print(\"V={}, T={}, P={}\".format(V, T, P))\n",
    "print(\"Actions: \", \", \".join([\"{:1.2f}\".format(a) for a in actions]))\n",
    "\n",
    "episodes_train = OrderbookEpisodesGenerator(filename=filename_train, episode_length=T*P)\n",
    "print(\"Length of episodes_train: {}\".format(len(episodes_train)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cached_episodes = list(episodes_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "STATE_DIM = len(state_variables)\n",
    "NUM_ACTIONS = len(actions)\n",
    "print(STATE_DIM)\n",
    "print(NUM_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_model(input_dim=2, output_dim=15):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=input_dim, activation='relu', init='zero'))\n",
    "    model.add(Dense(output_dim, activation='linear', init='zero'))\n",
    "    model.compile(loss='mse', optimizer='Adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_RL(orderbooks, V, T, period_length, epochs, model=None, gamma=0.95, DECAY_RATE=0.005, epsilon=1.,\n",
    "             bufferSize=50, batchSize=10, verbose=False, state_variables=['volume', 'time']):\n",
    "    \n",
    "    brain = RLAgent_NN(actions=actions, model=model, state_variables=state_variables, V=V, T=T, period_length=period_length)\n",
    "\n",
    "    state_dim = len(state_variables)    \n",
    "\n",
    "    MAX_EXPLORATION_RATE = 1.\n",
    "    MIN_EXPLORATION_RATE = 0.05\n",
    "\n",
    "    replay = Memory(bufferSize)\n",
    "    # stores tuples of (S, A, R, S')\n",
    "\n",
    "    for i_window, window in tqdm(enumerate(orderbooks)):\n",
    "        ots = OrderbookTradingSimulator(orderbooks=window, volume=V, tradingperiods=T,\n",
    "                                                        period_length=P)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            volume = V\n",
    "            startpoint = 0\n",
    "            \n",
    "            if random.random() < 0.5:\n",
    "                # randomly start at other states in environment\n",
    "                volume = random.randint(1, V)\n",
    "                startpoint = random.randint(0, T-1)\n",
    "                # print(\"random - V:{}, T:{}\".format(volume, startpoint))\n",
    "            \n",
    "            ots.reset(custom_starttime=startpoint, custom_startvolume=volume)\n",
    "            \n",
    "            action_history = []\n",
    "\n",
    "            acc_cost = 0\n",
    "            for step in range(startpoint, T):\n",
    "                time_left = T - step\n",
    "\n",
    "                timepoint = step*period_length\n",
    "                timepoint_next = min((step+1)*period_length, len(window)-1)\n",
    "                \n",
    "                ob_now = window[timepoint]\n",
    "                ob_next = window[timepoint_next]\n",
    "                \n",
    "                state = brain.generate_state(time_left=time_left,\n",
    "                                         volume_left=volume,\n",
    "                                         orderbook=ob_now)\n",
    "                \n",
    "                action = brain.choose_action(state=state, exploration=epsilon)\n",
    "                action_history.append(action)\n",
    "\n",
    "                limit = ob_now.get_ask() * (1. + (action/100.))\n",
    "                summary = ots.trade(limit=limit, verbose=False, extrainfo={'ACTION':action})  #agression_factor=action\n",
    "\n",
    "                volume = float(ots.volume)\n",
    "\n",
    "                new_state = brain.generate_state(time_left=time_left-1,\n",
    "                                                 volume_left=volume,\n",
    "                                                 orderbook=ob_next)\n",
    "                \n",
    "                cost = ots.history.cost.values[-1]\n",
    "\n",
    "                acc_cost += cost\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"{} {:1.1f} {} {:1.4f} {:1.4f}\".format(step, action, ots.volume, cost, acc_cost))\n",
    "\n",
    "                # if cost < 0:\n",
    "                #     print(\"{} {:1.2f} {:1.4f}Â {}\".format(state, action, cost, new_state))\n",
    "\n",
    "                replay.add((state, action, cost, new_state))\n",
    "                if (replay.size() >= batchSize):\n",
    "\n",
    "                    # wait for buffer to be filled, before getting started with training\n",
    "                    minibatch = replay.get_random_samples(batchSize)           \n",
    "\n",
    "                    X_train = []\n",
    "                    y_train = []\n",
    "                    for memory in minibatch:\n",
    "                        state_m, action_m, cost_m, new_state_m = memory\n",
    "                        \n",
    "\n",
    "                        qval_old = brain.model.predict(state_m.reshape(1, state_dim))               \n",
    "                        #print(qval_old)\n",
    "                        y = np.zeros((1, NUM_ACTIONS))\n",
    "                        y[:] = qval_old[:]\n",
    "\n",
    "                        qval_new_m = brain.model.predict(new_state_m.reshape(1, state_dim), batch_size=1)\n",
    "                        # display(qval_old)\n",
    "                        \n",
    "                        minQ = np.min(qval_new_m)\n",
    "                        # print(cost_m, gamma, minQ)\n",
    "                        update = cost_m + (gamma*minQ)\n",
    "                        # print(\"update\", update)\n",
    "                        action_m_idx = brain.get_action_index(action_m)\n",
    "\n",
    "                        y[0][action_m_idx] = update  # target output\n",
    "                        # display(y)\n",
    "                        X_train.append(state_m.reshape(state_dim,))\n",
    "                        y_train.append(y.reshape(NUM_ACTIONS,))\n",
    "                        \n",
    "                    X_train = np.array(X_train)\n",
    "                    y_train = np.array(y_train)\n",
    "                    display(X_train)\n",
    "                    display(y_train)\n",
    "                    return\n",
    "                    if verbose:\n",
    "                        print(\"Game #: %s\" % (i_window,))\n",
    "\n",
    "                    brain.model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "\n",
    "                state = new_state\n",
    "                if summary['done']:\n",
    "                    # display(ots.history)\n",
    "                    break\n",
    "\n",
    "            # reduce exploration rate\n",
    "            if epsilon > MIN_EXPLORATION_RATE:\n",
    "                epsilon = MAX_EXPLORATION_RATE *   math.exp(- DECAY_RATE * i_window)\n",
    "\n",
    "            info = \"   {} - {:4d}/{}: epsilon={:5.3f}, acc_cost: {:0.5f}, steps: {} (t={})\\n\"\\\n",
    "                    .format(e, i_window+1, epochs, epsilon,  acc_cost, step, ots.t)\n",
    "            #print(info)\n",
    "    return brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "episodes_train = OrderbookEpisodesGenerator(filename=filename_train, episode_length=T*P)\n",
    "# cached_episodes = list(episodes_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.23,  0.25],\n",
       "       [ 0.96,  0.75],\n",
       "       [ 1.  ,  1.  ],\n",
       "       [ 0.23,  0.5 ],\n",
       "       [ 0.63,  0.5 ],\n",
       "       [ 0.2 ,  0.5 ],\n",
       "       [ 0.91,  0.25],\n",
       "       [ 1.  ,  1.  ],\n",
       "       [ 0.63,  0.75],\n",
       "       [ 0.6 ,  1.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   6.01393938e-02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.44749960e-01,\n",
       "          0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.96703832e-01,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.00708085e-01,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          5.03902949e-02,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.64759782e-01,\n",
       "          0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.37017957e-01,\n",
       "          0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,  -3.83663620e-09,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'heatmap_Q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-2ab3841739a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m agent = train_RL(orderbooks=data[:], V=V, T=T, period_length=P, epochs=10, model=None,\n\u001b[1;32m      9\u001b[0m                  verbose=False, state_variables=['volume', 'time'])\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'heatmap_Q'"
     ]
    }
   ],
   "source": [
    "V=100\n",
    "T=4\n",
    "P=15\n",
    "\n",
    "data = cached_episodes  # episodes_train  # cached_episodes\n",
    "\n",
    "# plot_episode(episodes_train[1], volume=100)\n",
    "agent = train_RL(orderbooks=data[:], V=V, T=T, period_length=P, epochs=10, model=None,\n",
    "                 verbose=False, state_variables=['volume', 'time'])\n",
    "#agent.heatmap_Q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap_Q(model=model, vol_intervals=vol_intervals, T=T)\n",
    "plot_Q(model=model, z_represents='action', state_variables=['volume', 'time'])\n",
    "plot_Q(model=model, z_represents='Q', state_variables=['volume', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(V, T, P, epochs=1, overwrite_actions=None):\n",
    "    for i_episode in range(epochs):\n",
    "        ots = OrderbookTradingSimulator(orderbooks=episode_windows[1], volume=V,\n",
    "                                        tradingperiods=T, period_length=P)\n",
    "        plot_episode(episode_windows[1], volume=V)\n",
    "        time_left = P*T\n",
    "        volume = V\n",
    "\n",
    "        state = np.array([time_left, volume])  # , volume])\n",
    "        # state = discretize_state(state)\n",
    "\n",
    "        acc_cost = 0\n",
    "        for step in range(T):\n",
    "            qval = model.predict(state.reshape(1, STATE_DIM))\n",
    "            \n",
    "            action = actions[np.argmin(qval)]\n",
    "            \n",
    "            if overwrite_actions and step < len(overwrite_actions):\n",
    "                action = overwrite_actions[step]\n",
    "\n",
    "            # info = ots.trade(orderbooks, limit=lim, verbose=False)\n",
    "            info = ots.trade(agression_factor=action, verbose=False, extrainfo={'ACTION':action})\n",
    "\n",
    "            time_left -= 1\n",
    "            volume = ots.volume\n",
    "            new_state = np.array([time_left, volume])  # , volume])\n",
    "            cost = ots.history.cost.values[-1]\n",
    "\n",
    "            acc_cost += cost\n",
    "\n",
    "            state = new_state\n",
    "            if volume == 0:\n",
    "                break\n",
    "\n",
    "        info = \"{:4d}/{}: acc_cost: {:0.5f}, steps: {} (t={})\"\\\n",
    "                .format(i_episode+1, epochs, acc_cost, step, ots.t)\n",
    "        print(info)\n",
    "    return ots.history\n",
    "hist = run(V=V, T=T, P=P)  #, overwrite_actions=[0,0,0,0,0,0,0,0,0])\n",
    "display(hist)\n",
    "hist = run(V=V, T=T, P=P, overwrite_actions=[0.7]*10)\n",
    "display(hist)\n",
    "hist = run(V=V, T=T, P=P, overwrite_actions=[0.1, 0.2, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8])\n",
    "display(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
